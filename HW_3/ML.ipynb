{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e481de67-2b3c-4182-a10c-80a1a1f14ccf",
   "metadata": {},
   "source": [
    "## Подгрузка необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f185f3-c951-441a-95b2-cf1c5f8f56f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Управление отображением \n",
    "from IPython import display  \n",
    "\n",
    "# Работа с датами и временем\n",
    "from datetime import datetime, timedelta  \n",
    "\n",
    "# Работа с данными \n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "\n",
    "# Визуализация\n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns  \n",
    "\n",
    "# Обработка текста (NLP)\n",
    "import re  \n",
    "import spacy  \n",
    "import swifter  \n",
    "from nltk.corpus import stopwords  \n",
    "import nltk  \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer  \n",
    "\n",
    "# Машинное обучение\n",
    "from sklearn.preprocessing import MaxAbsScaler  \n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.svm import LinearSVC  \n",
    "from xgboost import XGBClassifier  \n",
    "from sklearn.metrics import classification_report, accuracy_score  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "# Оптимизация гиперпараметров\n",
    "import optuna  \n",
    "\n",
    "# Управление предупреждениями\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6fe086-3952-4632-845b-9b6de16013b4",
   "metadata": {},
   "source": [
    "## Обработка текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13c1d89-2c45-4e18-95f8-46c92f0bec48",
   "metadata": {},
   "source": [
    "В ходе обучения моделей для уменьшения размерности, а также для более корректных результатов, стоит провести обработку текста. Ниже была написана функция, которая приводит текст к нижнему регистру, удаляет лишние символы, проводит лемматизацию и удаляет стоп-слова. Однако из-за размерности данных, функция работает довольно долго. Поэтому для обучения и предсказаний моделей были заранее подготовлены два датасета с обработанными данными. Один тренировочный осонованный данных, которые удалось собрать, а другой контрольный, который используется для получения результатов на соревновании kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b407e67e-5df1-42f3-b159-2594e930ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_stopwords = set(stopwords.words(\"russian\"))\n",
    "nlp = spacy.load(\"ru_core_news_sm\")\n",
    "\n",
    "def preprocess_text_spacy(text):\n",
    "\n",
    "    # Удаление лишних символов и приведение текста к нижнему регистру\n",
    "    text = re.sub(r\"[^а-яА-ЯёЁ\\s]\", \"\", text.lower())\n",
    "    \n",
    "    # Лемматизация слов с помощью библиотеки spacy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Лемматизация и удаление стоп-слов\n",
    "    processed_words = [token.lemma_ for token in doc if token.lemma_ not in russian_stopwords and not token.is_punct]\n",
    "    \n",
    "    return \" \".join(processed_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf84d9b5-9236-447e-aa49-d9930d3c5125",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('lenta_data_processed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b146f8-384a-4e06-a963-01514f80d303",
   "metadata": {},
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe99c25-7e02-4184-86a2-794d5370197e",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde7b6d7-1e07-450d-a3e9-abd86b5e90dd",
   "metadata": {},
   "source": [
    "Для начала стоит задать baseline для предсказаний. Для этого обучим модель логистической регрессии на данных без какой-либо обработки с преобразованием в мешок слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7585df99-fc9d-4415-8a7b-60ca3b9e0de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['text']]\n",
    "y = df.topic\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8f7c551e-2421-4cd5-89e4-56f801907d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55011, 281024)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88      5798\n",
      "           1       0.92      0.88      0.90      2077\n",
      "           2       0.92      0.90      0.91      2057\n",
      "           3       0.89      0.90      0.89      3791\n",
      "           4       1.00      0.99      0.99      1687\n",
      "           5       0.95      0.95      0.95       655\n",
      "           6       0.88      0.70      0.78       270\n",
      "           7       0.95      0.90      0.92       878\n",
      "           8       0.95      0.88      0.91      1125\n",
      "\n",
      "    accuracy                           0.90     18338\n",
      "   macro avg       0.92      0.89      0.91     18338\n",
      "weighted avg       0.91      0.90      0.90     18338\n",
      "\n",
      "0.9047878721779911\n"
     ]
    }
   ],
   "source": [
    "bow = CountVectorizer(min_df=0.00001) # подбор гиперпараметров очень помогает\n",
    "bow.fit(X_train['text'])\n",
    "\n",
    "bow_train = bow.transform(X_train['text'])  # bow — bag of words (мешок слов)\n",
    "bow_test = bow.transform(X_test['text'])\n",
    "\n",
    "print(bow_train.shape)\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "bow_train = scaler.fit_transform(bow_train)\n",
    "bow_test = scaler.transform(bow_test)\n",
    "\n",
    "clf = LogisticRegression(max_iter=200, random_state=42)\n",
    "clf.fit(bow_train, y_train)\n",
    "pred = clf.predict(bow_test)\n",
    "\n",
    "print(classification_report(y_test, pred))\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "af387145-f892-4e90-af7c-4acab4f7164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = pd.read_csv(\"test_news.csv\")\n",
    "bow_test_c = bow.transform(Test['content'])\n",
    "bow_test_c = scaler.transform(bow_test_c)\n",
    "preds = clf.predict(bow_test_c)\n",
    "subm = pd.read_csv(\"base_submission_news.csv\")\n",
    "subm['topic'] = preds\n",
    "subm.to_csv(\"baseline_lenta.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042f7358-56bd-4253-8a29-6d27bdbc8f71",
   "metadata": {},
   "source": [
    "Baseline модель показывает себя весьма неплохо с результатом `accuracy = 0.819` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699a4ea3-7047-4a16-b17b-638831c5086d",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b985bb99-02dc-44db-8990-493450774f6f",
   "metadata": {},
   "source": [
    "Теперь будем обучать модели на обработанных данных с удалением стоп-слов и лемматизацией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "60e5eacc-1e9a-4778-bf12-cbba08292c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['processed_text']]\n",
    "y = df.topic\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f426b741-4541-4f88-b04a-c079e4e8cb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55011, 148003)\n"
     ]
    }
   ],
   "source": [
    "bow_transformer = CountVectorizer(min_df=0.00001) # подбор гиперпараметров очень помогает\n",
    "bow_transformer.fit(X_train['processed_text'])\n",
    "\n",
    "bow_train = bow_transformer.transform(X_train['processed_text'])  # bow — bag of words (мешок слов)\n",
    "bow_test = bow_transformer.transform(X_test['processed_text'])\n",
    "\n",
    "print(bow_train.shape)\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "bow_train = scaler.fit_transform(bow_train)\n",
    "bow_test = scaler.transform(bow_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e336a957-5d0b-4ab9-8495-ec6c28bc4b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88      5798\n",
      "           1       0.92      0.89      0.90      2077\n",
      "           2       0.92      0.90      0.91      2057\n",
      "           3       0.89      0.90      0.89      3791\n",
      "           4       0.99      0.99      0.99      1687\n",
      "           5       0.97      0.95      0.96       655\n",
      "           6       0.83      0.76      0.79       270\n",
      "           7       0.94      0.89      0.91       878\n",
      "           8       0.95      0.86      0.90      1125\n",
      "\n",
      "    accuracy                           0.90     18338\n",
      "   macro avg       0.92      0.89      0.90     18338\n",
      "weighted avg       0.90      0.90      0.90     18338\n",
      "\n",
      "0.9033155196858982\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=200, random_state=42)\n",
    "clf.fit(bow_train, y_train)\n",
    "pred = clf.predict(bow_test)\n",
    "\n",
    "print(classification_report(y_test, pred))\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3df288-f5e9-4525-a420-8822d82cf602",
   "metadata": {},
   "source": [
    "Как бы странно не было, но модель показывает себя чуточку хуже на обработанных данных. При этом значение имеет парметр в `train_test_split(stratify=y)`. Если его не использовать, то модель дает чуть более метрику `accuracy` на обработанных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b719dc-9a02-41c7-9f30-f07e3acc1377",
   "metadata": {},
   "source": [
    "Попробуем подобрать параметры модели так, чтобы она дала результат получше на обработанных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97682c77-8c91-42a4-8626-e495189b20bf",
   "metadata": {},
   "source": [
    "#### Подбор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bb71f7-eab3-4c78-aae0-32d2355f88a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg_obj(trial):\n",
    "    C = trial.suggest_loguniform('C', 1e-3, 1e2)  # Регуляризация\n",
    "    solver = trial.suggest_categorical('solver', ['lbfgs', 'saga'])# Алгоритм оптимизации\n",
    "    max_iter = trial.suggest_int('max_iter', 500, 5000)\n",
    "    mc = trial.suggest_categorical('multi_class', ['ovr', 'multinomial'])\n",
    "    cw = trial.suggest_categorical('class_weight', [None, 'balanced'])\n",
    "\n",
    "    clf = LogisticRegression(\n",
    "        max_iter=max_iter,\n",
    "        random_state=42,\n",
    "        multi_class=mc,\n",
    "        class_weight=cw,\n",
    "        C=C,\n",
    "        solver=solver,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "    clf.fit(bow_train, y_train)\n",
    "    \n",
    "    pred = clf.predict(bow_test)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(log_reg_obj, n_trials=25)\n",
    "\n",
    "# Лучшие параметры и результат\n",
    "print(\"Лучшие параметры:\", study.best_params)\n",
    "print(\"Лучшая точность:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700f212a-9fb1-4d96-9c62-ba94c361a3a6",
   "metadata": {},
   "source": [
    "С относительно быстрым подбором гиперпараметров удалось все-таки получить чуть более лучшую метрику `accuracy`. Output был очищен, чтобы не перенагружать ноутбук."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "37d86b42-aefe-4e05-adda-a0cfb26c0a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C': 1.176273146130487, 'solver': 'lbfgs', 'max_iter': 4488, 'multi_class': 'ovr', 'class_weight': 'balanced'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f3977e93-b2da-4e9f-9953-82ae3f4b09e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88      5798\n",
      "           1       0.91      0.91      0.91      2077\n",
      "           2       0.90      0.92      0.91      2057\n",
      "           3       0.88      0.90      0.89      3791\n",
      "           4       0.99      0.99      0.99      1687\n",
      "           5       0.95      0.96      0.96       655\n",
      "           6       0.76      0.83      0.79       270\n",
      "           7       0.92      0.93      0.92       878\n",
      "           8       0.91      0.89      0.90      1125\n",
      "\n",
      "    accuracy                           0.91     18338\n",
      "   macro avg       0.90      0.91      0.91     18338\n",
      "weighted avg       0.91      0.91      0.91     18338\n",
      "\n",
      "0.9051150616206783\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(**params, random_state=42)\n",
    "lr_clf.fit(bow_train, y_train)\n",
    "pred = lr_clf.predict(bow_test)\n",
    "\n",
    "print(classification_report(y_test, pred))\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "694d582a-5882-47ca-8ecf-23e5a90db763",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = pd.read_csv(\"test_news_processed.csv\")\n",
    "bow_test_c = bow_transformer.transform(Test['processed_content'])\n",
    "bow_test_c = scaler.transform(bow_test_c)\n",
    "preds = lr_clf.predict(bow_test_c)\n",
    "subm['topic'] = preds\n",
    "subm.to_csv(\"lr_lenta.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47e4bc3-9c65-4cf7-a7ab-abafde108a37",
   "metadata": {},
   "source": [
    "После тестирования на контрольных  данных с соревнования был замечен весьма странный результат. Не смотря на то, что по метрикам в ноутбуке все стало получше в плане метрик, в соревновании результат получился хуже с метрикой `accuracy = 0.809`. В какой-то степени исходя из этого возможно стоит использовать данные без удаления слов и лемматизации. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bc16fc-c0e7-47da-bdf1-31ec679be156",
   "metadata": {},
   "source": [
    "По предыдущим тестам, которые были сделаны в черновом ноутбуке, часть которых появится и в этом, преобразование TF-IDF не дало особо хороших результатов на контрольных данных с соревнования. Не смотря на то, что результаты по метрикам на собранных данных довольно значительно повышаются, на контрольных данных метрики понижаются. При этом всем лучше всего на соревновании показала себя модель XGBoost обученная на мешке слов с обработанными данными. Учитывая то, что результаты на соревновании kaggle понижаются на обработанных данных, стоит порпобовать обучить эту модель на необработанных данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39689ee3-6aea-4ea8-b6ab-71e74d0ec4d9",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdca5d49-2d53-4bf8-b800-53a88e085238",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['text']]\n",
    "y = df.topic\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42,stratify=y)\n",
    "\n",
    "bow = CountVectorizer(min_df=0.00001) \n",
    "bow.fit(X_train['text'])\n",
    "\n",
    "bow_train = bow.transform(X_train['text'])  \n",
    "bow_test = bow.transform(X_test['text'])\n",
    "\n",
    "print(bow_train.shape)\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "bow_train = scaler.fit_transform(bow_train)\n",
    "bow_test = scaler.transform(bow_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "259e7f87-f6c1-425b-a5c7-a9264250dbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [13:35:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89      5798\n",
      "           1       0.92      0.89      0.90      2077\n",
      "           2       0.93      0.90      0.91      2057\n",
      "           3       0.89      0.91      0.90      3791\n",
      "           4       1.00      0.99      0.99      1687\n",
      "           5       0.97      0.97      0.97       655\n",
      "           6       0.84      0.74      0.79       270\n",
      "           7       0.94      0.92      0.93       878\n",
      "           8       0.96      0.86      0.91      1125\n",
      "\n",
      "    accuracy                           0.91     18338\n",
      "   macro avg       0.92      0.90      0.91     18338\n",
      "weighted avg       0.91      0.91      0.91     18338\n",
      "\n",
      "0.9101864979823318\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 946, 'max_depth': 25, 'learning_rate': 0.02334486067381037,\n",
    "          'subsample': 0.7571222430291574, 'colsample_bytree': 0.6866556282657983,\n",
    "          'gamma': 0.09038470099513807}\n",
    "\n",
    "xg_clf = XGBClassifier(**params, random_state=42, scale_pos_weight = len(y_train) / (len(set(y_train)) * np.bincount(y_train)),\n",
    "                        objective = \"multi:softmax\", num_class = len(set(y_train)), use_label_encoder = False)\n",
    "xg_clf.fit(bow_train, y_train)\n",
    "pred = xg_clf.predict(bow_test)\n",
    "\n",
    "print(classification_report(y_test, pred))\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36043f39-3ebc-45dc-972b-3283acc3bbfa",
   "metadata": {},
   "source": [
    "Для экономии времени были использованы предыдущие параметры полученные с помощью optune для модели, которая проявила себя наилучшим образом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "38067596-682f-4030-b7ad-eaff1db5669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = pd.read_csv(\"test_news.csv\")\n",
    "bow_test_c = bow.transform(Test['content'])\n",
    "bow_test_c = scaler.transform(bow_test_c)\n",
    "preds = xg_clf.predict(bow_test_c)\n",
    "subm['topic'] = preds\n",
    "subm.to_csv(\"xgup_lenta.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d0bbf0-86f1-43a1-9500-390b6a2d90cf",
   "metadata": {},
   "source": [
    "К сожалению обучение на необработанных данных не дало какого либо прироста в метрике `accuracy`, которая была примерно равна на контрольных данных 0.824. Это, конечно, выше результатов, которые были получены в baseline модели, но как будет продемонстрированно далее, модель XGBoost все таки лучше работает на обработанных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ae75f964-785c-4317-8947-22549855fbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55011, 148003)\n"
     ]
    }
   ],
   "source": [
    "X = df[['processed_text']]\n",
    "y = df.topic\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "bow_transformer = CountVectorizer(min_df=0.00001) # подбор гиперпараметров очень помогает\n",
    "bow_transformer.fit(X_train['processed_text'])\n",
    "\n",
    "bow_train = bow_transformer.transform(X_train['processed_text'])  # bow — bag of words (мешок слов)\n",
    "bow_test = bow_transformer.transform(X_test['processed_text'])\n",
    "\n",
    "print(bow_train.shape)\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "bow_train = scaler.fit_transform(bow_train)\n",
    "bow_test = scaler.transform(bow_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "55ec9a9a-3b11-4b92-958b-306b12fa7135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# подбор параметров Optune\n",
    "def xg_obj(trial):\n",
    "    param = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 30),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.5),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"scale_pos_weight\": len(y_train) / (len(set(y_train)) * np.bincount(y_train)),\n",
    "        \"objective\": \"multi:softmax\",  # Многоклассовая классификация\n",
    "        \"num_class\": len(set(y_train)),  # Количество классов\n",
    "        \"random_state\": 42,\n",
    "        \"use_label_encoder\": False\n",
    "    }\n",
    "    \n",
    "    # Создание модели\n",
    "    clf = XGBClassifier(**param)\n",
    "\n",
    "    # Обучение\n",
    "    clf.fit(bow_train, y_train)\n",
    "\n",
    "    # Предсказания\n",
    "    pred = clf.predict(bow_test)\n",
    "\n",
    "    # Оценка качества\n",
    "    return accuracy_score(y_test, pred)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(xg_obj, n_trials=20)\n",
    "\n",
    "# Результаты\n",
    "print(\"Лучшие параметры:\", study.best_params)\n",
    "print(\"Лучшая точность:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b537c14b-ad9e-408d-886e-7a63e7a0cb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [14:29:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89      5798\n",
      "           1       0.92      0.90      0.91      2077\n",
      "           2       0.93      0.91      0.92      2057\n",
      "           3       0.89      0.92      0.90      3791\n",
      "           4       0.99      1.00      1.00      1687\n",
      "           5       0.97      0.96      0.96       655\n",
      "           6       0.87      0.78      0.82       270\n",
      "           7       0.95      0.93      0.94       878\n",
      "           8       0.95      0.88      0.91      1125\n",
      "\n",
      "    accuracy                           0.91     18338\n",
      "   macro avg       0.93      0.91      0.92     18338\n",
      "weighted avg       0.91      0.91      0.91     18338\n",
      "\n",
      "0.9132947976878613\n"
     ]
    }
   ],
   "source": [
    "spw = len(y_train) / (len(set(y_train)) * np.bincount(y_train))\n",
    "params = {'n_estimators': 946, 'max_depth': 25, 'learning_rate': 0.02334486067381037,\n",
    "          'subsample': 0.7571222430291574, 'colsample_bytree': 0.6866556282657983,\n",
    "          'gamma': 0.09038470099513807, 'scale_pos_weight': spw}\n",
    "\n",
    "xg_clf = XGBClassifier(**params, random_state=42, objective = \"multi:softmax\",\n",
    "                       num_class = len(set(y_train)), use_label_encoder = False)\n",
    "xg_clf.fit(bow_train, y_train)\n",
    "pred = xg_clf.predict(bow_test)\n",
    "\n",
    "print(classification_report(y_test, pred))\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f2f95658-ec58-48d9-b1f1-a4877019c945",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = pd.read_csv(\"test_news_processed.csv\")\n",
    "bow_test_c = bow_transformer.transform(Test['processed_content'])\n",
    "bow_test_c = scaler.transform(bow_test_c)\n",
    "preds = xg_clf.predict(bow_test_c)\n",
    "subm['topic'] = preds\n",
    "subm.to_csv(\"xgcp_lenta.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af295a8-8f70-4edf-9c5b-40309a2692c8",
   "metadata": {},
   "source": [
    "При обучении на обработанных данных метрика `accuracy` на контрольных данных была равна `0.83052`. Попробуем дообучить модель на всех данных. Возможно предсказания станут получше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e76be141-5556-424d-9086-9edb12393972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73349, 172390)\n"
     ]
    }
   ],
   "source": [
    "bow_transformer = CountVectorizer(min_df=0.00001) # подбор гиперпараметров очень помогает\n",
    "bow_transformer.fit(X['processed_text'])\n",
    "\n",
    "bow_X = bow_transformer.transform(X['processed_text'])  # bow — bag of words (мешок слов)\n",
    "\n",
    "print(bow_X.shape)\n",
    "\n",
    "scaler = MaxAbsScaler()\n",
    "bow_X = scaler.fit_transform(bow_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c69fd01d-8031-47d3-acf7-dbc58e39cd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [14:55:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     23191\n",
      "           1       1.00      1.00      1.00      8309\n",
      "           2       1.00      1.00      1.00      8228\n",
      "           3       1.00      1.00      1.00     15163\n",
      "           4       1.00      1.00      1.00      6749\n",
      "           5       1.00      1.00      1.00      2620\n",
      "           6       1.00      1.00      1.00      1079\n",
      "           7       1.00      1.00      1.00      3511\n",
      "           8       1.00      1.00      1.00      4499\n",
      "\n",
      "    accuracy                           1.00     73349\n",
      "   macro avg       1.00      1.00      1.00     73349\n",
      "weighted avg       1.00      1.00      1.00     73349\n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "spw = len(y) / (len(set(y)) * np.bincount(y))\n",
    "params = {'n_estimators': 946, 'max_depth': 25, 'learning_rate': 0.02334486067381037,\n",
    "          'subsample': 0.7571222430291574, 'colsample_bytree': 0.6866556282657983,\n",
    "          'gamma': 0.09038470099513807, 'scale_pos_weight': spw}\n",
    "\n",
    "xg_clf = XGBClassifier(**params, random_state=42, objective = \"multi:softmax\",\n",
    "                       num_class = len(set(y)), use_label_encoder = False)\n",
    "xg_clf.fit(bow_X, y)\n",
    "pred = xg_clf.predict(bow_X)\n",
    "\n",
    "print(classification_report(y, pred))\n",
    "print(accuracy_score(y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "da979fde-4119-465e-83d3-1e0bc075e0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = pd.read_csv(\"test_news_processed.csv\")\n",
    "bow_test_c = bow_transformer.transform(Test['processed_content'])\n",
    "bow_test_c = scaler.transform(bow_test_c)\n",
    "preds = xg_clf.predict(bow_test_c)\n",
    "subm['topic'] = preds\n",
    "subm.to_csv(\"xgcap_lenta.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2428e9c-7447-4a12-abf7-d3e3d6c90776",
   "metadata": {},
   "source": [
    "Результаты модели на контрольных данных чуть улучшились до значений метрики `accuracy = 0.83095`. Прирост не столь значим. Однако видно, что модель переобучена под данные. Возможно с этим можно что-то сделать. Попробуем применить L-2 регуляризацию для того, чтобы уменьшить переобучение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "805182d3-8d8f-46fe-9e39-e915e19f7b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [17:04:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     23191\n",
      "           1       1.00      1.00      1.00      8309\n",
      "           2       1.00      1.00      1.00      8228\n",
      "           3       1.00      1.00      1.00     15163\n",
      "           4       1.00      1.00      1.00      6749\n",
      "           5       1.00      1.00      1.00      2620\n",
      "           6       1.00      1.00      1.00      1079\n",
      "           7       1.00      1.00      1.00      3511\n",
      "           8       1.00      1.00      1.00      4499\n",
      "\n",
      "    accuracy                           1.00     73349\n",
      "   macro avg       1.00      1.00      1.00     73349\n",
      "weighted avg       1.00      1.00      1.00     73349\n",
      "\n",
      "0.9993728612523688\n"
     ]
    }
   ],
   "source": [
    "spw = len(y) / (len(set(y)) * np.bincount(y))\n",
    "params = {'n_estimators': 946, 'max_depth': 25, 'learning_rate': 0.02334486067381037,\n",
    "          'subsample': 0.7571222430291574, 'colsample_bytree': 0.6866556282657983,\n",
    "          'gamma': 0.09038470099513807, 'scale_pos_weight': spw}\n",
    "\n",
    "xg_clf = XGBClassifier(**params, random_state=42, objective = \"multi:softmax\",\n",
    "                       num_class = len(set(y)), use_label_encoder = False, reg_lambda = 10)\n",
    "xg_clf.fit(bow_X, y)\n",
    "pred = xg_clf.predict(bow_X)\n",
    "\n",
    "print(classification_report(y, pred))\n",
    "print(accuracy_score(y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "591e35e9-e529-48dd-892b-3c0f979c6742",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = pd.read_csv(\"test_news_processed.csv\")\n",
    "bow_test_c = bow_transformer.transform(Test['processed_content'])\n",
    "bow_test_c = scaler.transform(bow_test_c)\n",
    "preds = xg_clf.predict(bow_test_c)\n",
    "subm['topic'] = preds\n",
    "subm.to_csv(\"xgcapl2_lenta.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4955920-3648-4eb1-a3f9-e4d71a449c14",
   "metadata": {},
   "source": [
    "От переобучения к сожалению не удалось избавиться, а обучение модели занимает примерно минут 40, что довольно долго, если, например, для подбора параметров обучить где-то 25 моделей с помощью optune. Модель с L-2 регуляризацией дает метрики чуть хуже в плане метрики accuracy, которая равна примерно `0.82829`. Возможно я чуть позже попытаюсь еще раз подобрать параметры для улучшения результата, но это уже скорее будет идти как бонусный контент. Однако на текущий момент моделью, которая показывает себя наилучшим образом является переобученная модель XGBoost, которая показывает метрику accuracy, которая на 1.5% выше, чем у baseline модели. Это, конечно, не самый лучший результат, но добиться улучшения качества относительно baseline удалось."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d847ce20-e64d-471d-8af6-505a50b73cc0",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4eb696-d80a-445a-95cd-e45f52ad78d6",
   "metadata": {},
   "source": [
    "- В ходе обучения моделей логистической регрессии было выявлено, что модель дает более лучшие результаты в предсказаниях на контрольных данных при обучении на сырых собранных данных, переработанных в мешок слов. Можно предположить, что данное явление вызвано тем, что модель логиситческой регресии довольно простая, и из-за этого она лучше работает с избыточной информацией. Также возможно данный результат вызван тем, что данные были обработаны излишне.\n",
    "- В дальнейшем при обучении модели XGBoost ситуация была обратной. Модель показала себя лучше на обработанных данных. При этом эта модель модель показала себя лучше всего как на тренировочных данных, так и на контрольных данных после подбора гиперпараметров. Однако модель переобучается на тренировочных данных, что говорит о том, что в дальнейшем для получения лучших результатов вероятно стоит заново перебрать гиперпараметры, что весьма трудоемкий процесс часов на 10. Поэтому возможно это уже будет сделано после мягкого дедлайна уже в другом ноутбуке.\n",
    "- Если говорить про то почему модель XGBoost показала себя лучше в плане метрик, то скорее всего этот результат вызван тем, что модель XGBoost является более мощной моделью и может улавливать нелинейные зависимости.\n",
    "- Также вероятно на результаты могло повлиять возможно неправильное распределение новостей в кактегорию строительство, так как на сайте Lenta.ru отдельного раздела новостей с такой категорией нет, то пришлось немного извернуться и взять за эту категорию подраздел новостей связанных недвижимостью в экономическом разделе.\n",
    "- Хоть в данный ноутбук и не были включены разделы с TF-IDF обработкой текста и SVM моделью, но это было сделано намеренно, чтобы не растягивать ноутбук. SVM модель не показала каких-либо значимых отличий в результатах по сравнению с логистической регрессией на мешке слов, а при применении TF-IDF, которая выделяет важность слов в тексте, модели хоти и начинали работать лучше на тренировочных данных, но на контрольных данных модели проявляли себя довольно плохо."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b03073-2402-44b3-9615-e2679c0d62d3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
